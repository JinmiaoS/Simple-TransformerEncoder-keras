{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clean_Transformertest.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashwattrivedi/Simple-TransformerEncoder-keras/blob/master/Transformertest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "n22Pm3ObpiPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UVOQQEXT8pEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c3a2d1e4-7f50-488e-f6bf-5e773e364146"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/shashwattrivedi/Simple-TransformerEncoder-keras.git\n",
        "!git clone https://github.com/shashwattrivedi/Attention_visualizer.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Simple-TransformerEncoder-keras'...\n",
            "remote: Enumerating objects: 110, done.\u001b[K\n",
            "remote: Counting objects: 100% (110/110), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 110 (delta 62), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (110/110), 591.06 KiB | 3.16 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "Cloning into 'Attention_visualizer'...\n",
            "remote: Enumerating objects: 44, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 44 (delta 10), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QWm7qIwb9-Yn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp Simple-TransformerEncoder-keras/Transformer/* .\n",
        "!cp Simple-TransformerEncoder-keras/Polarity_model/* .\n",
        "!cp Attention_visualizer/attention_visualizer.py ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-eWq9fCd9Hf",
        "colab_type": "code",
        "outputId": "ca95a116-8595-4e79-985c-28ef47c7de3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "vTn6xggTiedc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from TransformerEncoder import TransformerEncoder\n",
        "from TrainablePositionalEmbeddings import TransformerPositionalEmbedding\n",
        "from utility import *\n",
        "from keras.layers import Input,Dense,Embedding,Add,Lambda,Flatten,Reshape\n",
        "from keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from preprocess import *\n",
        "from attention_visualizer import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QVXq9_V_PFZo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data directory\n",
        "glovePath = '/content/gdrive/My Drive/Colab Notebooks/glove.6B.50d.txt'\n",
        "dataPath  = 'polarity.pkl'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eqjnjho_O2aw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Hyper-parameters**"
      ]
    },
    {
      "metadata": {
        "id": "b4rcD1BSd9Hw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "word_embeddings_dim = 50\n",
        "heads               = 2\n",
        "query_dim           = 32\n",
        "value_dim           = 32\n",
        "positional_ff_dim   = 128\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ZSLuLzId9Ic",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Reading data and Preprocess"
      ]
    },
    {
      "metadata": {
        "id": "9L-MjFdrPXRJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reading\n",
        "data,labels,label_names,val,val_labels = load_data_from_pickle(dataPath)\n",
        "\n",
        "#Preprocess\n",
        "nlp           = spacy.load('en')\n",
        "textprocessor = TextProcessor(nlp)\n",
        "data          = textprocessor.fit_and_transform(data)\n",
        "val           = textprocessor.transform(val)\n",
        "\n",
        "#Train-test Split\n",
        "train_X, test_X, train_y, test_y = data, val, labels, val_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkCA1SoKd9H0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocess input"
      ]
    },
    {
      "metadata": {
        "id": "ba46hoRBd9IR",
        "colab_type": "code",
        "outputId": "dbd58f2c-23bd-439d-caf8-c3e4229faab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "glove_embeddings  = loadGlove(glovePath)\n",
        "emb_mat           = getEmbMatrix(glove_embeddings,textprocessor.tokenizer.word_index,word_embeddings_dim)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17682, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7JeWJAD7d9Il",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model"
      ]
    },
    {
      "metadata": {
        "id": "jcCgAJmvd9Ir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getPolarityModel(max_sequence_len,embedding_matrix,word_embeddings_dim,\n",
        "                     transformer_depth,heads,\n",
        "                     query_dim,value_dim,positional_ff_dim):\n",
        "    \n",
        "    X                             = Input(shape=(max_sequence_len,),dtype='int32')\n",
        "    #mask_layer                    = Reshape((max_sequence_len,1))(MaskLayer()(X)) #for masking\n",
        "    wordEmb                       = Embedding(len(emb_mat), \n",
        "                                              word_embeddings_dim, \n",
        "                                              weights=[emb_mat], \n",
        "                                              trainable=False,\n",
        "                                              name='Word_Embedding')\n",
        "    positional_embedding_layer    = TransformerPositionalEmbedding(name='Positional_embedding')\n",
        "    \n",
        "    next_step_input               = positional_embedding_layer(wordEmb(X))\n",
        "    #next_step_input               = Lambda(lambda x: x[0]*x[1])([next_step_input, mask_layer]) \n",
        "\n",
        "    attention=[None for i in range(transformer_depth)]\n",
        "    for i in range(transformer_depth):\n",
        "            next_step_input,attention[i] =TransformerEncoder(word_embeddings_dim,\n",
        "                                                             heads,\n",
        "                                                             query_dim,\n",
        "                                                             value_dim,\n",
        "                                                             positional_ff_dim,\n",
        "                                                             dropout_rate= 0.1,\n",
        "                                                             name= 'Transformer'+str(i))(next_step_input) \n",
        "            \n",
        "    \n",
        "    sentence_representation       = Lambda(lambda x: x[:,0,:])(next_step_input)\n",
        "    review_class                  = Dense(1,activation='sigmoid',name='Polarity')(sentence_representation)\n",
        "\n",
        "    model                         = Model(inputs=[X],outputs=[review_class,attention[-1]])\n",
        "    \n",
        "    return model\n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fCEpAQ5ed9Iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifier = getPolarityModel(textprocessor.max_seq_len,\n",
        "                              emb_mat,word_embeddings_dim,\n",
        "                              transformer_depth=1,\n",
        "                              heads = 4,\n",
        "                              query_dim = 128,\n",
        "                              value_dim = 128,\n",
        "                              positional_ff_dim=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44kZ4oOdd9I-",
        "colab_type": "code",
        "outputId": "0ad51b04-a29a-4dab-97ad-7bba0cba1b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.compile('nadam',\n",
        "                  loss={'Polarity': 'binary_crossentropy'},\n",
        "                  metrics={'Polarity': 'accuracy'}                \n",
        "                  )\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Output \"lambda_6\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"lambda_6\" during training.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "4M_e4Pd0d9JD",
        "colab_type": "code",
        "outputId": "ea1ea2d3-c814-4dce-f186-e9bab117523a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.fit([train_X],[train_y],batch_size=32,epochs=5,shuffle=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10433/10433 [==============================] - 5s 511us/step - loss: 0.5188 - Polarity_loss: 0.5188 - Polarity_acc: 0.7415\n",
            "Epoch 2/5\n",
            "10433/10433 [==============================] - 5s 498us/step - loss: 0.4972 - Polarity_loss: 0.4972 - Polarity_acc: 0.7538\n",
            "Epoch 3/5\n",
            "10433/10433 [==============================] - 5s 498us/step - loss: 0.4898 - Polarity_loss: 0.4898 - Polarity_acc: 0.7633\n",
            "Epoch 4/5\n",
            "10433/10433 [==============================] - 5s 496us/step - loss: 0.4890 - Polarity_loss: 0.4890 - Polarity_acc: 0.7609\n",
            "Epoch 5/5\n",
            "10433/10433 [==============================] - 5s 497us/step - loss: 0.4818 - Polarity_loss: 0.4818 - Polarity_acc: 0.7657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f170a8b44a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "UO6fbwUed9JI",
        "colab_type": "code",
        "outputId": "6875dacf-ef53-4e31-9d32-bc3751b8cf9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.evaluate([test_X],test_y)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 0s 148us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46649920296669006, 0.46649920296669006, 0.765]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "a2jv0wdVeYrQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def try_this_sentence(sentence,head):\n",
        "  inp = textprocessor.transform([sentence])\n",
        "  y_pred, attention = classifier.predict(inp)\n",
        "  print(\"The prediction value is \" + str (y_pred[0][0]) + \" That is \" +str(label_names[y_pred[0][0]>=0.5]))\n",
        "  \n",
        "  input_sent = textprocessor.backtransform(inp)[0].split()\n",
        "  return display_attention(input_sent+[\"\" for _ in range(len(attention[0,head-1,0,:])-len(input_sent))],list(map(float,attention[0,head-1,0,:])))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5mUOtqJDoeVa",
        "colab_type": "code",
        "outputId": "c43d1498-07db-4119-c340-66b9d3983a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "try_this_sentence('I liked the movie, it was entertaining',3)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction value is 0.77394795 That is positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\t<script src=\"https://d3js.org/d3.v4.min.js\"></script>\n",
              "\t<style>\n",
              "\thtml, body {\n",
              "\tmargin: 0;\n",
              "\tpadding: 0;\n",
              "\t}\n",
              "\n",
              "\t.tooltip {\n",
              "\tposition: relative;\n",
              "\tdisplay: inline-block;\n",
              "\tborder-bottom: 1px dotted black;\n",
              "\t}\n",
              "\t.tooltip:hover .tooltiptext {\n",
              "\tvisibility: visible;\n",
              "\t}\n",
              "\n",
              "\t.tooltip .tooltiptext {\n",
              "\tvisibility: hidden;\n",
              "\tfont-size:15px;\n",
              "\twidth: 60px;\n",
              "\tbackground-color: black;\n",
              "\tcolor: #fff;\n",
              "\ttext-align: center;\n",
              "\tborder-radius: 6px;\n",
              "\tpadding: 1px 0;\n",
              "\tposition: absolute;\n",
              "\n",
              "\tleft: 50%;\n",
              "\tmargin-left: -60px;\n",
              "\t}\n",
              "\n",
              "\t</style>\n",
              "\t<script>\n",
              "\tvar dataset =[[\"This\",0.4],[\"is\",0.3],[\"a\",0.2],[\"text\",0.4]]\n",
              "\tvar seconddataset = [\"Hello\",\"World\"]\n",
              "\n",
              "\tfunction float2int (value) {\n",
              "\treturn value | 0;\n",
              "\t}\n",
              "\n",
              "\tfunction tohex(fraction)\n",
              "\t{\n",
              "\tvar value = float2int(255 * fraction);\n",
              "\tif(value==0)\n",
              "\treturn \"00\"\n",
              "\tvar mapping = ['A','B','C','D','E','F'];\n",
              "\tvar hex=\"\";\n",
              "\n",
              "\twhile(value!==0)\n",
              "\t{\n",
              "\tvar curr= value%16;\n",
              "\tif(curr >9)\n",
              "\t  {\n",
              "\t    hex = mapping[curr-10] + hex;\n",
              "\t  }\n",
              "\telse\n",
              "\t  hex = curr + hex;\n",
              "\tvalue = float2int(value/16);\n",
              "\t}\n",
              "\n",
              "\treturn hex;\n",
              "\t}\n",
              "\n",
              "\td3.select('#text')\n",
              "\t.selectAll('#text')\n",
              "\t.data([{\"token\": \"cls\", \"weight\": 0.0008763921214267612}, {\"token\": \"i\", \"weight\": 0.36157265305519104}, {\"token\": \"liked\", \"weight\": 0.26129215955734253}, {\"token\": \"the\", \"weight\": 0.0025497947353869677}, {\"token\": \"movie\", \"weight\": 0.007346566766500473}, {\"token\": \"it\", \"weight\": 0.018570411950349808}, {\"token\": \"was\", \"weight\": 0.021223431453108788}, {\"token\": \"entertaining\", \"weight\": 0.011456470005214214}, {\"token\": \"\", \"weight\": 0.002335020573809743}, {\"token\": \"\", \"weight\": 0.009666744619607925}, {\"token\": \"\", \"weight\": 0.003787001594901085}, {\"token\": \"\", \"weight\": 0.0033172001130878925}, {\"token\": \"\", \"weight\": 0.0052879322320222855}, {\"token\": \"\", \"weight\": 0.002809366909787059}, {\"token\": \"\", \"weight\": 0.007384666707366705}, {\"token\": \"\", \"weight\": 0.004208933562040329}, {\"token\": \"\", \"weight\": 0.007970312610268593}, {\"token\": \"\", \"weight\": 0.00581377325579524}, {\"token\": \"\", \"weight\": 0.0028268545866012573}, {\"token\": \"\", \"weight\": 0.011883781291544437}, {\"token\": \"\", \"weight\": 0.006207763217389584}, {\"token\": \"\", \"weight\": 0.009808010421693325}, {\"token\": \"\", \"weight\": 0.01443718746304512}, {\"token\": \"\", \"weight\": 0.0035997137892991304}, {\"token\": \"\", \"weight\": 0.007057063281536102}, {\"token\": \"\", \"weight\": 0.017462698742747307}, {\"token\": \"\", \"weight\": 0.006958134938031435}, {\"token\": \"\", \"weight\": 0.000944692175835371}, {\"token\": \"\", \"weight\": 0.003024924313649535}, {\"token\": \"\", \"weight\": 0.010304070077836514}, {\"token\": \"\", \"weight\": 0.006439207121729851}, {\"token\": \"\", \"weight\": 0.0008901839610189199}, {\"token\": \"\", \"weight\": 0.001751742442138493}, {\"token\": \"\", \"weight\": 0.021645881235599518}, {\"token\": \"\", \"weight\": 0.004358035046607256}, {\"token\": \"\", \"weight\": 0.00283024157397449}, {\"token\": \"\", \"weight\": 0.009566206485033035}, {\"token\": \"\", \"weight\": 0.01050654612481594}, {\"token\": \"\", \"weight\": 0.0021190636325627565}, {\"token\": \"\", \"weight\": 0.003005438717082143}, {\"token\": \"\", \"weight\": 0.002221759408712387}, {\"token\": \"\", \"weight\": 0.003765593282878399}, {\"token\": \"\", \"weight\": 0.0027988224755972624}, {\"token\": \"\", \"weight\": 0.0043879239819943905}, {\"token\": \"\", \"weight\": 0.005043363198637962}, {\"token\": \"\", \"weight\": 0.013811469078063965}, {\"token\": \"\", \"weight\": 0.006667581852525473}, {\"token\": \"\", \"weight\": 0.0041647544130682945}, {\"token\": \"\", \"weight\": 0.004027163609862328}, {\"token\": \"\", \"weight\": 0.004236529115587473}, {\"token\": \"\", \"weight\": 0.0036828897427767515}, {\"token\": \"\", \"weight\": 0.0036799844820052385}, {\"token\": \"\", \"weight\": 0.003614833578467369}, {\"token\": \"\", \"weight\": 0.004193928092718124}, {\"token\": \"\", \"weight\": 0.004207569174468517}, {\"token\": \"\", \"weight\": 0.0037816420663148165}, {\"token\": \"\", \"weight\": 0.0035880026407539845}, {\"token\": \"\", \"weight\": 0.004157205577939749}, {\"token\": \"\", \"weight\": 0.0038716313429176807}, {\"token\": \"\", \"weight\": 0.003839562414214015}, {\"token\": \"\", \"weight\": 0.003582805162295699}, {\"token\": \"\", \"weight\": 0.0035139580722898245}, {\"token\": \"\", \"weight\": 0.00403082137927413}, {\"token\": \"\", \"weight\": 0.0040338593535125256}])\n",
              "\t.enter()\n",
              "\t.append('tspan')\n",
              "\t.style('font-family','verdana')\n",
              "\t.style('background-color', function(d,i){return '#FF' +tohex(1-d.weight) +tohex(1-d.weight) ;})\n",
              "\t.style('margin','2px')\n",
              "\t.attr(\"class\",\"tooltip\")\n",
              "\t.style('font-size',function(d){return  18 +0*d.weight + \"px\" ;})\n",
              "\t.attr(\"onmouseover\", \"handleMouseOver()\")\n",
              "\t.text(function(d){\n",
              "\treturn d.token+\" \" ;\n",
              "\t})\n",
              "\t.append('span')\n",
              "\t.attr('class',\"tooltiptext\")\n",
              "\t.text(function(d){\n",
              "\treturn Math.round(d.weight*10000)/100;\n",
              "\t});\n",
              "\t</script>\n",
              "\t<div id = 'text' style=\"margin-left:50px;\"></div>\n",
              "\t"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "y-g-AIq6m7Va",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "444f3873-db75-4296-b788-1db86e435298"
      },
      "cell_type": "code",
      "source": [
        "try_this_sentence('I liked the movie, it was entertaining',4)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The prediction value is 0.77394795 That is positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\t<script src=\"https://d3js.org/d3.v4.min.js\"></script>\n",
              "\t<style>\n",
              "\thtml, body {\n",
              "\tmargin: 0;\n",
              "\tpadding: 0;\n",
              "\t}\n",
              "\n",
              "\t.tooltip {\n",
              "\tposition: relative;\n",
              "\tdisplay: inline-block;\n",
              "\tborder-bottom: 1px dotted black;\n",
              "\t}\n",
              "\t.tooltip:hover .tooltiptext {\n",
              "\tvisibility: visible;\n",
              "\t}\n",
              "\n",
              "\t.tooltip .tooltiptext {\n",
              "\tvisibility: hidden;\n",
              "\tfont-size:15px;\n",
              "\twidth: 60px;\n",
              "\tbackground-color: black;\n",
              "\tcolor: #fff;\n",
              "\ttext-align: center;\n",
              "\tborder-radius: 6px;\n",
              "\tpadding: 1px 0;\n",
              "\tposition: absolute;\n",
              "\n",
              "\tleft: 50%;\n",
              "\tmargin-left: -60px;\n",
              "\t}\n",
              "\n",
              "\t</style>\n",
              "\t<script>\n",
              "\tvar dataset =[[\"This\",0.4],[\"is\",0.3],[\"a\",0.2],[\"text\",0.4]]\n",
              "\tvar seconddataset = [\"Hello\",\"World\"]\n",
              "\n",
              "\tfunction float2int (value) {\n",
              "\treturn value | 0;\n",
              "\t}\n",
              "\n",
              "\tfunction tohex(fraction)\n",
              "\t{\n",
              "\tvar value = float2int(255 * fraction);\n",
              "\tif(value==0)\n",
              "\treturn \"00\"\n",
              "\tvar mapping = ['A','B','C','D','E','F'];\n",
              "\tvar hex=\"\";\n",
              "\n",
              "\twhile(value!==0)\n",
              "\t{\n",
              "\tvar curr= value%16;\n",
              "\tif(curr >9)\n",
              "\t  {\n",
              "\t    hex = mapping[curr-10] + hex;\n",
              "\t  }\n",
              "\telse\n",
              "\t  hex = curr + hex;\n",
              "\tvalue = float2int(value/16);\n",
              "\t}\n",
              "\n",
              "\treturn hex;\n",
              "\t}\n",
              "\n",
              "\td3.select('#text')\n",
              "\t.selectAll('#text')\n",
              "\t.data([{\"token\": \"cls\", \"weight\": 0.001492249546572566}, {\"token\": \"i\", \"weight\": 0.03629401698708534}, {\"token\": \"liked\", \"weight\": 0.09153793752193451}, {\"token\": \"the\", \"weight\": 0.0004937619087286294}, {\"token\": \"movie\", \"weight\": 0.016726769506931305}, {\"token\": \"it\", \"weight\": 0.002856727922335267}, {\"token\": \"was\", \"weight\": 0.0007289718487299979}, {\"token\": \"entertaining\", \"weight\": 0.539556086063385}, {\"token\": \"\", \"weight\": 0.00340062752366066}, {\"token\": \"\", \"weight\": 0.0019403835758566856}, {\"token\": \"\", \"weight\": 0.007457563187927008}, {\"token\": \"\", \"weight\": 0.0039007854647934437}, {\"token\": \"\", \"weight\": 0.0025844371411949396}, {\"token\": \"\", \"weight\": 0.004060481209307909}, {\"token\": \"\", \"weight\": 0.006299290340393782}, {\"token\": \"\", \"weight\": 0.005921697709709406}, {\"token\": \"\", \"weight\": 0.006574714556336403}, {\"token\": \"\", \"weight\": 0.005379489157348871}, {\"token\": \"\", \"weight\": 0.0032953363843262196}, {\"token\": \"\", \"weight\": 0.0019026201916858554}, {\"token\": \"\", \"weight\": 0.0052367509342730045}, {\"token\": \"\", \"weight\": 0.0022998761851340532}, {\"token\": \"\", \"weight\": 0.000986588653177023}, {\"token\": \"\", \"weight\": 0.004964166320860386}, {\"token\": \"\", \"weight\": 0.006725320592522621}, {\"token\": \"\", \"weight\": 0.0024319675285369158}, {\"token\": \"\", \"weight\": 0.019513197243213654}, {\"token\": \"\", \"weight\": 0.010290357284247875}, {\"token\": \"\", \"weight\": 0.009079407900571823}, {\"token\": \"\", \"weight\": 0.004890906158834696}, {\"token\": \"\", \"weight\": 0.005976010113954544}, {\"token\": \"\", \"weight\": 0.005696750711649656}, {\"token\": \"\", \"weight\": 0.002419808879494667}, {\"token\": \"\", \"weight\": 0.0023819738999009132}, {\"token\": \"\", \"weight\": 0.0034900701139122248}, {\"token\": \"\", \"weight\": 0.004699577111750841}, {\"token\": \"\", \"weight\": 0.017704350873827934}, {\"token\": \"\", \"weight\": 0.014880801551043987}, {\"token\": \"\", \"weight\": 0.004192485939711332}, {\"token\": \"\", \"weight\": 0.001631595310755074}, {\"token\": \"\", \"weight\": 0.002562121255323291}, {\"token\": \"\", \"weight\": 0.0036125292535871267}, {\"token\": \"\", \"weight\": 0.0031898978631943464}, {\"token\": \"\", \"weight\": 0.021601978689432144}, {\"token\": \"\", \"weight\": 0.002343464409932494}, {\"token\": \"\", \"weight\": 0.0029375257436186075}, {\"token\": \"\", \"weight\": 0.007187785115092993}, {\"token\": \"\", \"weight\": 0.003313407301902771}, {\"token\": \"\", \"weight\": 0.009167231619358063}, {\"token\": \"\", \"weight\": 0.008557415567338467}, {\"token\": \"\", \"weight\": 0.003958995919674635}, {\"token\": \"\", \"weight\": 0.00916566327214241}, {\"token\": \"\", \"weight\": 0.004039866849780083}, {\"token\": \"\", \"weight\": 0.00417352095246315}, {\"token\": \"\", \"weight\": 0.00428744638338685}, {\"token\": \"\", \"weight\": 0.004649574402719736}, {\"token\": \"\", \"weight\": 0.004184648394584656}, {\"token\": \"\", \"weight\": 0.003945459146052599}, {\"token\": \"\", \"weight\": 0.004146539140492678}, {\"token\": \"\", \"weight\": 0.004063622560352087}, {\"token\": \"\", \"weight\": 0.003707160009071231}, {\"token\": \"\", \"weight\": 0.004306773189455271}, {\"token\": \"\", \"weight\": 0.00457347696647048}, {\"token\": \"\", \"weight\": 0.004428003914654255}])\n",
              "\t.enter()\n",
              "\t.append('tspan')\n",
              "\t.style('font-family','verdana')\n",
              "\t.style('background-color', function(d,i){return '#FF' +tohex(1-d.weight) +tohex(1-d.weight) ;})\n",
              "\t.style('margin','2px')\n",
              "\t.attr(\"class\",\"tooltip\")\n",
              "\t.style('font-size',function(d){return  18 +0*d.weight + \"px\" ;})\n",
              "\t.attr(\"onmouseover\", \"handleMouseOver()\")\n",
              "\t.text(function(d){\n",
              "\treturn d.token+\" \" ;\n",
              "\t})\n",
              "\t.append('span')\n",
              "\t.attr('class',\"tooltiptext\")\n",
              "\t.text(function(d){\n",
              "\treturn Math.round(d.weight*10000)/100;\n",
              "\t});\n",
              "\t</script>\n",
              "\t<div id = 'text' style=\"margin-left:50px;\"></div>\n",
              "\t"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "WinEH-tgn5dk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}